{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9322223a",
   "metadata": {},
   "source": [
    "# COMP 3610 Assignment 1   \n",
    "\n",
    "# Part 1 Data Ingestion and Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aa5f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests \n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "677c650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIP_URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet\"\n",
    "ZONE_URL = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\"\n",
    "\n",
    "RAW_DIR = \"data/raw\"\n",
    "os.makedirs(RAW_DIR, exist_ok=True)\n",
    "\n",
    "def download_with_progress(url, save_path, expected_min_size_mb=100):\n",
    "    print(f\"Downloading {url}...\")\n",
    "    try:\n",
    "        response = requests.get(url, stream=True, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        block_size = 1024 * 1024 \n",
    "        \n",
    "        with open(save_path, 'wb') as f, tqdm(\n",
    "            desc=save_path,\n",
    "            total=total_size,\n",
    "            unit='iB',\n",
    "            unit_scale=True,\n",
    "            unit_divisor=1024,\n",
    "        ) as bar:\n",
    "            for chunk in response.iter_content(chunk_size=block_size):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    bar.update(len(chunk))\n",
    "        \n",
    "        actual_size_mb = os.path.getsize(save_path) / (1024 * 1024)\n",
    "        print(f\"Downloaded {actual_size_mb:.1f} MB to {save_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Download failed: {e}\")\n",
    "        if os.path.exists(save_path):\n",
    "            os.remove(save_path)  \n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb21271c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data/raw\\yellow_tripdata_2024-01.parquet: 100%|██████████| 47.6M/47.6M [00:03<00:00, 15.7MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 47.6 MB to data/raw\\yellow_tripdata_2024-01.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data/raw\\taxi_zone_lookup.csv: 12.0kiB [00:00, 12.1MiB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 0.0 MB to data/raw\\taxi_zone_lookup.csv\n",
      "\n",
      "Downloads finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trip_path = os.path.join(RAW_DIR, \"yellow_tripdata_2024-01.parquet\")\n",
    "zone_path = os.path.join(RAW_DIR, \"taxi_zone_lookup.csv\")\n",
    "\n",
    "if os.path.exists(trip_path):\n",
    "    os.remove(trip_path)\n",
    "if os.path.exists(zone_path):\n",
    "    os.remove(zone_path)\n",
    "\n",
    "# Download again\n",
    "download_with_progress(TRIP_URL, trip_path,)\n",
    "download_with_progress(ZONE_URL, zone_path,)\n",
    "\n",
    "print(\"\\nDownloads finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "292f7976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Part 1 Data Validation ===\n",
      "Reading trip data from data/raw/yellow_tripdata_2024-01.parquet...\n",
      "Reading zone data from data/raw/taxi_zone_lookup.csv...\n",
      "All expected columns are present in the trip data.\n",
      "All expected columns are present in the zone data.\n",
      "Datetime columns have been validated.\n",
      "\n",
      "=== Part 1 Data Summary ===\n",
      "Total number of trips: 2964624\n",
      "Zone rows : 265\n",
      "\n",
      "Sample trip data:\n",
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         2  2024-01-01 00:57:55   2024-01-01 01:17:43              1.0   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0           1.72         1.0                  N           186            79   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0             2         17.7    1.0      0.5         0.0           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \n",
      "0                    1.0          22.7                   2.5          0.0  \n",
      "\n",
      "Sample zone data:\n",
      "   LocationID Borough            Zone service_zone\n",
      "0           1     EWR  Newark Airport          EWR\n",
      "\n",
      "Validation and summary completed successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Part 1 Data Validation ===\")\n",
    "\n",
    "trip_path = \"data/raw/yellow_tripdata_2024-01.parquet\"\n",
    "zone_path = \"data/raw/taxi_zone_lookup.csv\"\n",
    "\n",
    "print (f\"Reading trip data from {trip_path}...\")\n",
    "df = pd.read_parquet(trip_path)\n",
    "\n",
    "print (f\"Reading zone data from {zone_path}...\")\n",
    "zones_df = pd.read_csv(zone_path)\n",
    "\n",
    "expected_trip_columns = [\n",
    "    'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
    "    'PULocationID', 'DOLocationID', 'passenger_count',\n",
    "    'trip_distance', 'fare_amount', 'tip_amount',\n",
    "    'total_amount', 'payment_type'\n",
    "]\n",
    "\n",
    "missing_trip_columns = [col for col in expected_trip_columns if col not in df.columns]\n",
    "if missing_trip_columns:\n",
    "    raise ValueError(f\"Missing columns in trip data: {missing_trip_columns}\")\n",
    "print(\"All expected columns are present in the trip data.\")\n",
    "\n",
    "expected_zone_columns = ['LocationID', 'Borough', 'Zone', 'service_zone']\n",
    "missing_zone_columns = [col for col in expected_zone_columns if col not in zones_df.columns]\n",
    "if missing_zone_columns:\n",
    "    raise ValueError(f\"Missing columns in zone data: {missing_zone_columns}\")\n",
    "print(\"All expected columns are present in the zone data.\")\n",
    "\n",
    "df ['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'], errors='coerce')\n",
    "df ['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'], errors='coerce')\n",
    "\n",
    "invalid_dates = df['tpep_pickup_datetime'].isna().sum() + df['tpep_dropoff_datetime'].isna().sum()\n",
    "if invalid_dates > 0:\n",
    "    print(f\"Warning: Found {invalid_dates} invalid datetime entries in the trip data.\")\n",
    "print(\"Datetime columns have been validated.\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n=== Part 1 Data Summary ===\")\n",
    "print(f\"Total number of trips: {len(df)}\")\n",
    "print(f\"Zone rows : {len(zones_df)}\")\n",
    "\n",
    "\n",
    "print(\"\\nSample trip data:\")\n",
    "print(df.head(1))\n",
    "\n",
    "print(\"\\nSample zone data:\")\n",
    "print(zones_df.head(1))\n",
    "\n",
    "print (\"\\nValidation and summary completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65b9897",
   "metadata": {},
   "source": [
    "# Part 1 Complete add more after done "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
